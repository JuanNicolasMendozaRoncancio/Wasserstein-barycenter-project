{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f29d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16a1db",
   "metadata": {},
   "source": [
    "# My idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fd576",
   "metadata": {},
   "source": [
    "We are going to solve the folloeing problem\n",
    "\n",
    "$$\n",
    "            \\begin{dcases}\n",
    "                \\min_{p \\geq 0, \\textcolor{red}{\\pi \\in Y}} \\sum_{m=1}^{M}\\frac{1}{M}\\sum_{r=1}^{R}\\sum_{s=1}^{S^{m}} \\| \\xi_r - \\zeta_{s}^{m}\\|^2 \\pi_{rs}^{m} \\\\\n",
    "                \\textbf{s.t }\\sum_{r=1}^R \\pi_{rs}^{(m)} = q_s^{(m)}, \\quad \n",
    "                \\sum_{s=1}^{S^{(m)}} \\pi_{rs}^{(m)} = p_r \n",
    "            \\end{dcases}\n",
    "$$\n",
    "\n",
    "With constrains such as: $Y = \\{\\pi \\,\\large| \\,||\\pi^{(m)}||_F \\leq \\tau\\}$ or $\\sum_{s} \\pi_{rs} \\leq c_r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9e102",
   "metadata": {},
   "source": [
    "So my idea is: As the transport plan are matrices we could solve the following problem:\n",
    "\n",
    "$$\n",
    "\\begin{dcases}\n",
    "    \\min_{Y} \\frac{1}{2} ||P - \\pi ||_F^2\\\\\n",
    "\n",
    "    \\textbf{s.t }\\sum_{r=1}^R P_{rs}^{(m)} = q_s^{(m)}, \\quad \n",
    "    \\sum_{s=1}^{S^{(m)}} P_{rs}^{(m)} = p_r\n",
    "\\end{dcases}\n",
    "$$\n",
    "\n",
    "That is we could find the projection of $\\pi$ on $Y \\cap \\mathcal{U}(\\nu^{m},\\mu)$ where $\\mathcal{U}(\\nu^{m},\\mu)$ is the set of couplings betewn $\\nu^{m},\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1078522",
   "metadata": {},
   "source": [
    "## ADMM (Converges on the frobenius norm and the couplings politope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d1633",
   "metadata": {},
   "source": [
    "We can reformulate the problem as follows:\n",
    "\n",
    "$$\n",
    "\\begin{dcases}\n",
    "    \\min_{P,Z} \\frac{1}{2} ||P - \\pi ||_F^2 + \\mathcal{I}_{\\mathcal{U}(\\nu^{m},\\mu)} (P) + \\mathcal{I}_{\\mathcal{B}_{\\tau}}(Z) \\\\   \n",
    "\n",
    "    \\textbf{s.t } P - Z = 0\n",
    "\\end{dcases}\n",
    "$$\n",
    "\n",
    "This leads to tink on the ADMM algo. The augmented lagrangian is:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}_{\\rho}(P,Z,Y) = \\frac{1}{2} ||P - \\pi ||_F^2 + \\mathcal{I}_{\\mathcal{U}(\\nu^{m},\\mu)} (P) + \\mathcal{I}_{\\mathcal{B}_{\\tau}}(Z) + \\langle Y, P-Z \\rangle + \\frac{\\rho}{2}||P-Z||_F^2\n",
    "$$\n",
    "\n",
    "To simplify this we see that:\n",
    "\n",
    "$$\n",
    "\\frac{\\rho}{2} ||X + \\frac{Y}{\\rho}||^2 - \\frac{1}{2\\rho}||Y||^2 = \\frac{\\rho}{2}\\big( ||X||^2 + 2\\langle X, \\frac{Y}{\\rho} \\rangle + ||\\frac{Y}{\\rho}||^2\\big)-\\frac{1}{2\\rho}||Y||^2\\\\\n",
    "=\\frac{\\rho}{2}||X||^2 + \\langle X, Y \\rangle \n",
    "$$\n",
    "\n",
    "If $X = P-Z$: \n",
    "\n",
    "$$\n",
    "\\langle P-Z, Y \\rangle + \\frac{\\rho}{2}||P-Z||^2 =\\frac{\\rho}{2} ||P - Z + \\frac{Y}{\\rho}||^2 -\\frac{1}{2}||\\frac{Y}{\\rho}||^2\n",
    "$$\n",
    "\n",
    "If we do $U = \\frac{Y}{\\rho}$ we get the new lagrangian:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}_{\\rho}(P,Z,U) = \\frac{1}{2} ||P - \\pi ||_F^2 + \\mathcal{I}_{\\mathcal{U}(\\nu^{m},\\mu)} (P) + \\mathcal{I}_{\\mathcal{B}_{\\tau}}(Z) + \\frac{\\rho}{2} ||P - Z + U||^2 -\\frac{1}{2}||U||^2\n",
    "$$\n",
    "\n",
    "So we propoce the following iterations:\n",
    "\n",
    "$$\n",
    "P^{k+1} = \\argmin_{P \\in \\mathcal{U}(\\nu^{m},\\mu)}  \\frac{1}{2} ||P - \\pi ||_F^2  + \\frac{\\rho}{2} ||P - (Z^K - U^K)||^2\\\\\n",
    "\n",
    "Z^{k+1} = \\argmin_{Z \\in \\mathcal{B}_\\tau}  \\frac{\\rho}{2} ||P^{k+1} - Z + U^k||^2\\\\\n",
    "\n",
    "U^{k+1} = U^k + P^{k+1} - Z^{k+1}\n",
    "$$\n",
    "\n",
    "We see that, for instance:\n",
    "\n",
    "$$\n",
    "Z^{k+1} = \\argmin_{Z \\in \\mathcal{B}_\\tau}  \\frac{\\rho}{2} ||P^{k+1} + U^k  - Z||^2 = \\mathcal{P}_{\\mathcal{B}_\\tau}(P^{k+1} + U^k) = \\begin{cases}\n",
    "                            P^{k+1} + U^k \\text{ if } ||P^{k+1} + U^k||_F \\leq \\tau\\\\\n",
    "                            \\frac{\\tau}{||P^{k+1} + U^k||_F} P^{k+1} + U^k \\text{ if } ||P^{k+1} + U^k||_F > \\tau        \n",
    "                        \\end{cases}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "if we take a look onto the first actualization:\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} ||P - \\pi ||_F^2  + \\frac{\\rho}{2} ||P - (Z^K - U^K)||^2 = \\frac{1}{2}||P||^2 - \\langle P,\\pi \\rangle + \\frac{1}{2}||\\pi||^2 + \\frac{\\rho}{2}\\big( ||P||^2 - 2\\langle P, Z^k - U^k \\rangle + ||Z^k - U^k||^2\\big)\\\\\n",
    "= \\frac{1}{2}||P||^2 - \\langle P,\\pi \\rangle + \\frac{\\rho}{2}||P||^2 - \\rho\\langle P, Z^k - U^k \\rangle\\\\\\\n",
    "= \\frac{1+\\rho}{2}||P||^2 - \\langle P,\\pi + \\rho(Z^k - U^k) \\rangle\n",
    "$$\n",
    "\n",
    "We want to complete the square so:\n",
    "\n",
    "$$\n",
    "\\frac{1+\\rho}{2}||P-M||^2 = \\frac{1+\\rho}{2}||P||^2 - \\langle P,\\pi + \\rho(Z^k - U^k) \\rangle\\\\\n",
    "= \\frac{1+\\rho}{2}||P||^2 - (1+\\rho)\\langle P,M \\rangle + \\frac{1+\\rho}{2}||M||^2\n",
    "$$\n",
    "\n",
    "If $M$ does not depend on $P$ we can ignore it on the minimization:\n",
    "\n",
    "$$\n",
    "(1+\\rho)\\langle P,M \\rangle = \\langle P,\\pi + \\rho(Z^k - U^k) \\rangle\\\\\n",
    "M = \\frac{\\pi + \\rho(Z^k - U^k)}{1+\\rho}\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "P^{k+1} = \\argmin_{P \\in \\mathcal{U}(\\nu^{m},\\mu)}  \\frac{1+\\rho}{2}||P-\\frac{\\pi + \\rho(Z^k - U^k)}{1+\\rho}||^2 = \\mathcal{P}_{\\mathcal{U}(\\nu^{m},\\mu)} \\big(\\frac{\\pi + \\rho(Z^k - U^k)}{1+\\rho} \\big)\\\\\n",
    "$$\n",
    "\n",
    "Finally we have:\n",
    "\n",
    "$$\n",
    "P^{k+1} = \\mathcal{P}_{\\mathcal{U}(\\nu^{m},\\mu)} \\big(\\frac{\\pi + \\rho(Z^k - U^k)}{1+\\rho} \\big)\\\\\n",
    "\n",
    "Z^{k+1} = \\begin{cases}\n",
    "            P^{k+1} + U^k \\text{ if } ||P^{k+1} + U^k||_F \\leq \\tau\\\\\n",
    "            \\frac{\\tau}{||P^{k+1} + U^k||_F} P^{k+1} + U^k \\text{ if } ||P^{k+1} + U^k||_F > \\tau        \n",
    "        \\end{cases}\\\\\n",
    "U^{k+1} = U^k + P^{k+1} - Z^{k+1}\n",
    "\n",
    "$$\n",
    "\n",
    "The only problem is solving the update of $P$, lets suppose that projection exists (PROVE), we can use Dikstra algorihm for this as the set $\\mathcal{U}(\\nu^{m},\\mu) = \\{P : P1 = \\nu\\} \\cap \\{P : P^{T}1 = \\mu\\} \\cap \\{P : P \\geq 0\\}$ each one of the is convex, we will name them $C_1, C_2, C_3$.\n",
    "\n",
    "We can see (PROVE) the the projection of a matrix $Q \\in \\mathbb{R}^{m\\times n}$ on each of the previous sets are:\n",
    "\n",
    "$$\n",
    "\\mathcal{P}_{C_1}(Q) = Q + \\frac{\\nu^m - Q1}{n}1^{T}\\\\\n",
    "\\mathcal{P}_{C_2}(Q) = Q + 1\\frac{\\mu - Q^T1^T}{m}\\\\\n",
    "\\mathcal{P}_{C_3}(Q) = \\max\\{Q,0\\}\n",
    "$$\n",
    "\n",
    "So, Dikstra is as follows:\n",
    "\n",
    "Let $P^0 = A$ (matrix to project), $R_1 = R_2 = R_3 = 0$ and:\n",
    "\n",
    "$$\n",
    "Q_1 = P^{K} + R_1^{K}\\\\\n",
    "P_1 = \\mathcal{P}_{C_1}(Q_1)\\\\\n",
    "R_1^{k+1} = Q_1 - P_1\\\\\n",
    "Q_2 = P_1 + R_2^{k}\\\\\n",
    "P_2 = \\mathcal{P}_{C_2}(Q_2)\\\\\n",
    "R_2^{k+1} = Q_2 - P_2\\\\\n",
    "Q_3 = P_2 + R_3^{k}\\\\\n",
    "P^{k+1} = \\mathcal{P}_{C_3}(Q_3)\\\\\n",
    "R_3^{k+1} = Q_3 - P^{k+1}\\\\\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d39874",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de3f37",
   "metadata": {},
   "source": [
    "Lets implement this algo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485dcbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_rows(Q, nu):\n",
    "    correction = (nu - Q.sum(axis=1))[:, None] / Q.shape[1]\n",
    "    return Q + correction\n",
    "\n",
    "def proj_cols(Q, mu):\n",
    "    correction = (mu - Q.sum(axis=0))[None, :] / Q.shape[0]\n",
    "    return Q + correction\n",
    "\n",
    "def proj_simplex(Q):\n",
    "    return np.maximum(Q, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dykstra_coupling(\n",
    "    A,\n",
    "    nu,\n",
    "    mu,\n",
    "    max_iter=500,\n",
    "    tol=1e-8,\n",
    "    verbose=False\n",
    "):\n",
    "    P = A.copy()\n",
    "    R1 = np.zeros_like(A)\n",
    "    R2 = np.zeros_like(A)\n",
    "    R3 = np.zeros_like(A)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "\n",
    "        P_old = P.copy()\n",
    "\n",
    "        Q1 = P + R1\n",
    "        P1 = proj_rows(Q1, nu)\n",
    "        R1 = Q1 - P1\n",
    "\n",
    "        Q2 = P1 + R2\n",
    "        P2 = proj_cols(Q2, mu)\n",
    "        R2 = Q2 - P2\n",
    "\n",
    "        Q3 = P2 + R3\n",
    "        P = proj_simplex(Q3)\n",
    "        R3 = Q3 - P\n",
    "\n",
    "        err = np.linalg.norm(P - P_old, ord='fro') / (np.linalg.norm(P_old, ord='fro') + 1e-12)\n",
    "\n",
    "        if verbose and k % 50 == 0:\n",
    "            print(f\"Iter {k:4d} | err = {err:.2e}\")\n",
    "\n",
    "        if err < tol:\n",
    "            if verbose:\n",
    "                print(f\"Converged at {k} iterations.\")\n",
    "            break\n",
    "\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1de8ce",
   "metadata": {},
   "source": [
    "Lets prove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e027be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q:\n",
      "[[19.89586324 17.92702513 11.23067502 12.70142359]\n",
      " [17.76155577 11.94742612 19.63911264 11.54894467]\n",
      " [12.29422204 13.53855468 18.66601178 18.50994024]]\n",
      "\n",
      "Row sums of Q: [61.75498698 60.8970392  63.00872873]\n",
      "Target row sums (nu): [0.2959353  0.13146063 0.57260407]\n",
      "\n",
      "Column sums of Q: [49.95164105 43.41300593 49.53579944 42.76030849]\n",
      "Target column sums (mu): [0.29222391 0.42515395 0.25470622 0.02791592]\n"
     ]
    }
   ],
   "source": [
    "Q = np.array([[np.random.uniform(10, 20) for _ in range(4)] for _ in range(3)])\n",
    "\n",
    "nu = np.array(np.random.dirichlet(np.ones(3)))\n",
    "mu = np.array(np.random.dirichlet(np.ones(4)))\n",
    "\n",
    "print(\"Initial Q:\")\n",
    "print(Q)\n",
    "\n",
    "print(\"\\nRow sums of Q:\", Q.sum(axis=1))\n",
    "print(\"Target row sums (nu):\", nu)\n",
    "\n",
    "print(\"\\nColumn sums of Q:\", Q.sum(axis=0))\n",
    "print(\"Target column sums (mu):\", mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd75d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected P:\n",
      "[[0.16076328 0.13517202 0.         0.        ]\n",
      " [0.13146063 0.         0.         0.        ]\n",
      " [0.         0.28998194 0.25470622 0.02791592]]\n",
      "\n",
      "Row sums of P: [0.2959353  0.13146063 0.57260407]\n",
      "Target row sums (nu): [0.2959353  0.13146063 0.57260407]\n",
      "\n",
      "Difference in row sums: [ 1.19423693e-10  2.51845822e-10 -6.99540426e-11]\n",
      "\n",
      "Column sums of P: [0.29222391 0.42515395 0.25470622 0.02791592]\n",
      "\n",
      "Difference in column sums: [-6.99538205e-11  6.21613316e-11  1.54554591e-10  1.54553263e-10]\n"
     ]
    }
   ],
   "source": [
    "P = dykstra_coupling(Q, nu, mu, verbose=False, max_iter=10000, tol=1e-10)\n",
    "\n",
    "print(\"Projected P:\")\n",
    "print(P)\n",
    "\n",
    "print(\"\\nRow sums of P:\", P.sum(axis=1))\n",
    "\n",
    "print(\"Target row sums (nu):\", nu)\n",
    "print(\"\\nDifference in row sums:\", P.sum(axis=1) - nu)\n",
    "\n",
    "print(\"\\nColumn sums of P:\", P.sum(axis=0))\n",
    "print(\"\\nDifference in column sums:\", P.sum(axis=0) - mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497cbbc",
   "metadata": {},
   "source": [
    "Now we takle the $Z$ projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0397600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobennius_ball_proj(Q, tau):\n",
    "    norm_Q = np.linalg.norm(Q, ord='fro')\n",
    "    if norm_Q <= tau:\n",
    "        return Q\n",
    "    else:\n",
    "        return (tau / norm_Q) * Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579d4ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of Q:\n",
      "54.8401567377503\n",
      "Frobenius norm of projected Q:\n",
      "15.000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Frobenius norm of Q:\")\n",
    "print(np.linalg.norm(Q, ord='fro'))\n",
    "proj= frobennius_ball_proj(Q, 15)\n",
    "print(\"Frobenius norm of projected Q:\")\n",
    "print(np.linalg.norm(proj, ord='fro'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8f790",
   "metadata": {},
   "source": [
    "Now lets prove our algoritm with a \"random\" matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d4a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimentions of our matrix Q\n",
    "n,m = np.random.randint(3,10), np.random.randint(3,10)\n",
    "#Random matrix Q and radius tau\n",
    "Q = np.random.uniform(-10,10,(n,m))\n",
    "tau = np.random.uniform(5,15)\n",
    "\n",
    "#Random variables mu an nu\n",
    "mu = np.random.dirichlet(np.ones(m))\n",
    "nu = np.random.dirichlet(np.ones(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68192517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q:\n",
      "[[-8.81891451 -6.37541128  6.45944639 -6.17378659  0.7672133  -9.90684242\n",
      "   7.40641844]\n",
      " [-0.44982799 -3.72675105 -5.33748406  6.29167305 -2.40575704  5.86990324\n",
      "   5.70539417]\n",
      " [ 5.72825188  8.00504984 -2.26213947 -2.92827986  1.57895424 -0.1684029\n",
      "  -2.36792087]\n",
      " [ 8.87269101  9.30473141 -1.33363908 -7.77401413 -1.20959235 -4.92136785\n",
      "  -7.39976006]\n",
      " [-6.2032275   2.20752057 -8.60955678  1.64193424  0.0621944  -1.43890914\n",
      "   2.97994927]\n",
      " [-9.00349697  8.44933844 -0.45139588  6.12507485 -0.62123997 -0.12430876\n",
      "   5.12874294]]\n",
      "Frobenius norm of Q: 35.79785636381666\n",
      "\n",
      "Vector nu:\n",
      "[0.25328964 0.01216681 0.18613003 0.03969973 0.43783353 0.07088025]\n",
      "Vector mu:\n",
      "[0.27268444 0.11379236 0.14649463 0.06773576 0.17003506 0.16895428\n",
      " 0.06030346]\n",
      "Scalar tau:\n",
      "10.151858079261265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Matrix Q:\\n{Q}\")\n",
    "print(f\"Frobenius norm of Q: {np.linalg.norm(Q, ord='fro')}\\n\")\n",
    "print(f\"Vector nu:\\n{nu}\")\n",
    "print(f\"Vector mu:\\n{mu}\")\n",
    "print(f\"Scalar tau:\\n{tau}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf305194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def admm_transport_projection(\n",
    "    pi,\n",
    "    nu,\n",
    "    mu,\n",
    "    tau,\n",
    "    rho=1.0,\n",
    "    max_iter=200,\n",
    "    tol=1e-6,\n",
    "    dykstra_iters=10,\n",
    "    verbose=False\n",
    "):\n",
    "\n",
    "    P = pi.copy()\n",
    "    Z = pi.copy()\n",
    "    U = np.zeros_like(pi)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "\n",
    "        P_old = P.copy()\n",
    "\n",
    "        # ---- P update ----\n",
    "        M = (pi + rho * (Z - U)) / (1.0 + rho)\n",
    "        P = dykstra_coupling(\n",
    "            M, nu, mu,\n",
    "            max_iter=dykstra_iters\n",
    "        )\n",
    "\n",
    "        # ---- Z update ----\n",
    "        Z = frobennius_ball_proj(P + U, tau)\n",
    "\n",
    "        # ---- dual update ----\n",
    "        U = U + P - Z\n",
    "\n",
    "        # ---- stopping ----\n",
    "        r_norm = np.linalg.norm(P - Z, ord='fro')\n",
    "        s_norm = np.linalg.norm(P - P_old, ord='fro')\n",
    "\n",
    "        if verbose and k % 20 == 0:\n",
    "            print(\n",
    "                f\"Iter {k:4d} | \"\n",
    "                f\"primal = {r_norm:.2e} | \"\n",
    "                f\"dual = {s_norm:.2e}\"\n",
    "            )\n",
    "\n",
    "        if r_norm < tol and s_norm < tol:\n",
    "            if verbose:\n",
    "                print(f\"Convergió en {k} iteraciones\")\n",
    "            break\n",
    "\n",
    "    return P, Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16bf1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "P,Z = admm_transport_projection(\n",
    "    Q, nu, mu, tau, rho = 1.0, verbose=False, max_iter=500000, tol=1e-8, dykstra_iters=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0074d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected P:\n",
      "\n",
      "[[0.         0.         0.16272106 0.         0.         0.\n",
      "  0.07652989]\n",
      " [0.         0.         0.         0.         0.         0.01471944\n",
      "  0.        ]\n",
      " [0.20399681 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.05756651 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.04236469 0.         0.06974103 0.17204034 0.15624012\n",
      "  0.        ]\n",
      " [0.         0.07343292 0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "Frobennius norm of P: 0.37886680420331936\n",
      "\n",
      "Row sum of P diference: [-0.01403869  0.00255263  0.01786678  0.01786678  0.00255265  0.00255268]\n",
      "\n",
      "Column sum of P diference: [-0.01112112  0.00200526  0.01622643  0.00200527  0.00200527  0.00200528\n",
      "  0.01622643]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Projected P:\\n\")\n",
    "print(P)\n",
    "print(f\"Frobennius norm of P: {np.linalg.norm(P, ord='fro')}\\n\")\n",
    "print(f\"Row sum of P diference: {P.sum(axis=1) - nu}\\n\")\n",
    "print(f\"Column sum of P diference: {P.sum(axis=0) - mu}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552c760",
   "metadata": {},
   "source": [
    "## Proximal Gradient + barrier (Converges only on the frobenius norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03269e1",
   "metadata": {},
   "source": [
    "Remember taht our problem is:\n",
    "\n",
    "$$\n",
    "\\begin{dcases}\n",
    "    \\min_{\\mathcal{B}_\\tau} \\frac{1}{2} ||P - \\pi ||_F^2\\\\\n",
    "\n",
    "    \\textbf{s.t }\\sum_{r=1}^R P_{rs}^{(m)} = q_s^{(m)}, \\quad \n",
    "    \\sum_{s=1}^{S^{(m)}} P_{rs}^{(m)} = p_r\n",
    "\\end{dcases}\n",
    "$$\n",
    "\n",
    "We can relax this probem by setting:\n",
    "\n",
    "$$\n",
    "\\min \\frac{1}{2} ||P - \\pi ||_F^2 + \\frac{\\lambda}{2} ||P1-\\nu||_2^2 + \\frac{\\beta}{2} ||P^T 1- \\mu||_2^2\\\\\n",
    "\n",
    "\\textbf{s.t } P \\geq 0, P \\in \\mathcal{B}_\\tau\n",
    "$$\n",
    "\n",
    "Lets calculate the gradient of the prevuios function, lets call it $F(P)$:\n",
    "\n",
    "$$\n",
    "\\nabla F(P) =P - \\pi + \\lambda(P1-\\nu)1^T + \\beta 1(P^T 1 - \\mu)^T\n",
    "$$\n",
    "\n",
    "So the algo would look like:\n",
    "\n",
    "$$\n",
    "\\bar{P}^{k+1} = P^k - \\xi\\nabla F(P^k)\\\\\n",
    "P^{k+1} = \\mathcal{P}_{\\mathcal{B}_\\tau}(P^{k,+})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db970a01",
   "metadata": {},
   "source": [
    "Lets prove our algo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a82ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q:\n",
      "[[ 6.94617972 -6.23651455  0.73751336  5.8402345   8.55951826 -6.93005099\n",
      "  -3.28438114  2.50769877]\n",
      " [ 8.57916458  5.6076939  -0.2756286   8.08306244  6.5484072   7.02559511\n",
      "   8.07498024  4.01999045]\n",
      " [ 0.15798905 -3.64294244 -9.97974674  4.65856153  0.11174263  4.30463063\n",
      "   5.98020255 -8.52134627]\n",
      " [ 8.29108061  2.50682074  8.49956537 -6.16491754 -9.99326984 -5.33087101\n",
      "  -7.15262262  7.66869989]\n",
      " [-0.18109     4.3970061   6.51999685 -5.30664642 -0.77182969  8.17298109\n",
      "  -9.92035715  1.7379725 ]\n",
      " [ 1.20359372 -2.52256672 -5.96712583  5.83061841  9.51642489 -2.5035926\n",
      "   0.72064171  2.156774  ]\n",
      " [ 5.79501081  9.50154427 -3.91916999  7.91948883  0.46834937  1.53072088\n",
      "   4.2197532  -2.83974769]\n",
      " [ 8.11199148 -1.11963896 -8.146214    9.37907912  5.974018    0.34361907\n",
      "   6.46851926  1.64537556]]\n",
      "Frobenius norm of Q: 47.53592012813715\n",
      "\n",
      "Vector nu:\n",
      "[0.11861878 0.17602565 0.01947676 0.1823152  0.0217832  0.15210973\n",
      " 0.23961732 0.09005336]\n",
      "Vector mu:\n",
      "[0.04413    0.40818031 0.03555856 0.01660049 0.00710444 0.03036107\n",
      " 0.25022397 0.20784116]\n",
      "Scalar tau:\n",
      "6.211969114558373\n"
     ]
    }
   ],
   "source": [
    "#Dimentions of our matrix Q\n",
    "n,m = np.random.randint(3,10), np.random.randint(3,10)\n",
    "#Random matrix Q and radius tau\n",
    "Q = np.random.uniform(-10,10,(n,m))\n",
    "tau = np.random.uniform(5,15)\n",
    "\n",
    "#Random variables mu an nu\n",
    "mu = np.random.dirichlet(np.ones(m))\n",
    "nu = np.random.dirichlet(np.ones(n))\n",
    "\n",
    "print(f\"Matrix Q:\\n{Q}\")\n",
    "print(f\"Frobenius norm of Q: {np.linalg.norm(Q, ord='fro')}\\n\")\n",
    "print(f\"Vector nu:\\n{nu}\")\n",
    "print(f\"Vector mu:\\n{mu}\")\n",
    "print(f\"Scalar tau:\\n{tau}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19a66ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximal_gradient_transport_projection(\n",
    "    pi,\n",
    "    nu,\n",
    "    mu,\n",
    "    tau,\n",
    "    lambda_=1.0,\n",
    "    beta = 1.0,\n",
    "    step_size=1.0,\n",
    "    max_iter=20000,\n",
    "    tol=1e-8,\n",
    "    verbose=False\n",
    "):\n",
    "    P = pi.copy()\n",
    "\n",
    "    for k in range(max_iter):\n",
    "\n",
    "        P_old = P.copy()\n",
    "\n",
    "        firstpart =  (P - pi) \n",
    "        secondpart =  lambda_ * (P.sum(axis=1) - nu)[:, None]\n",
    "        thirdpart =  beta * (P.sum(axis=0) - mu)[None, :]\n",
    "\n",
    "        gradient = firstpart + secondpart + thirdpart\n",
    "\n",
    "        P -= step_size * gradient\n",
    "\n",
    "        # ---- Projection step ----\n",
    "        P = proj_simplex(P)\n",
    "        \n",
    "        P = frobennius_ball_proj(P, tau)\n",
    "\n",
    "        # ---- Stopping criteria ----\n",
    "        rel_err = (\n",
    "            np.linalg.norm(P - P_old, ord='fro')\n",
    "            / (np.linalg.norm(P_old, ord='fro') + 1e-12)\n",
    "        )\n",
    "\n",
    "        if verbose and k % 50 == 0:\n",
    "            marg_r = np.linalg.norm(P.sum(axis=1) - nu)\n",
    "            marg_c = np.linalg.norm(P.sum(axis=0) - mu)\n",
    "            print(\n",
    "                f\"Iter {k:4d} | \"\n",
    "                f\"rel = {rel_err:.2e} | \"\n",
    "                f\"rows = {marg_r:.2e} | \"\n",
    "                f\"cols = {marg_c:.2e}\"\n",
    "            )\n",
    "\n",
    "        if rel_err < tol:\n",
    "            if verbose:\n",
    "                print(f\"Convergió en {k} iteraciones\")\n",
    "            break\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c31c9c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected P:\n",
      "[[0.71116754 0.71116775 0.71116753 0.71116752 0.71116752 0.71116752\n",
      "  0.71116766 0.71116764]\n",
      " [1.05534558 1.05534579 1.05534557 1.05534556 1.05534555 1.05534557\n",
      "  1.0553457  1.05534567]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.13059795 0.13059817 0.13059795 0.13059793 0.13059793 0.13059795\n",
      "  0.13059807 0.13059805]\n",
      " [0.91195966 0.91195988 0.91195965 0.91195965 0.91195964 0.91195965\n",
      "  0.91195978 0.91195976]\n",
      " [1.43660411 1.43660433 1.4366041  1.4366041  1.43660408 1.4366041\n",
      "  1.43660423 1.4366042 ]\n",
      " [0.53990593 0.53990614 0.53990591 0.53990591 0.53990591 0.53990592\n",
      "  0.53990605 0.53990602]]\n",
      "Frobennius norm of P: 6.211969114558373\n",
      "\n",
      "Row sum of P diference: [ 5.5707219   8.26673934 -0.01947676 -0.1823152   1.02300081  7.14356794\n",
      " 11.25321593  4.22919444]\n",
      "\n",
      "Column sum of P diference: [4.74145077 4.37740176 4.75002215 4.76898019 4.77847619 4.75521964\n",
      " 4.53535753 4.57774019]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P = proximal_gradient_transport_projection(\n",
    "    Q, nu, mu, tau, lambda_=1e10, beta=1000.0,)\n",
    "\n",
    "print(\"Projected P:\")\n",
    "print(P)\n",
    "\n",
    "print(f\"Frobennius norm of P: {np.linalg.norm(P, ord='fro')}\\n\")\n",
    "print(f\"Row sum of P diference: {P.sum(axis=1) - nu}\\n\")\n",
    "print(f\"Column sum of P diference: {P.sum(axis=0) - mu}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881ce86",
   "metadata": {},
   "source": [
    "## How does MAM works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ccc26",
   "metadata": {},
   "source": [
    "We are given $m$ measures with support:\n",
    "\n",
    "$$\n",
    "\\text{Supp}(\\nu^{(m)}) = \\{\\zeta^{m}_{S^{i}}\\}_{i = 1,...,S^m}\n",
    "$$\n",
    "\n",
    "The $m$-th measure has $S^{m}$ elements on its support. And the goal measure has $R$ points. We also have: $\\nu^{m} = \\sum_{s = 1}^{S^m} q_s^{(m)} \\delta_{\\zeta_s^{(m)}}$ that is: $q_s^{(m)}$ is the mass on the point $\\zeta_s^{(m)}$. Taking this into account lets look at the MAM algo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba940651",
   "metadata": {},
   "source": [
    "**Step 0: input**\n",
    "\n",
    "1: Given $\\rho > 0$, the cost matrix and initial point $c, \\theta^0 \\in \\mathbb{R}^{R \\times T}$, and $a \\in \\Delta_M$ as in (5.2a), set\n",
    "$$k \\leftarrow 0 \\text{ and } p_r^{(m),0} \\leftarrow \\sum_{s=1}^{S^{(m)}} \\theta_{rs}^{(m),0}, \\quad r=1,\\ldots,R, \\quad m=1,\\ldots,M$$\n",
    "\n",
    "2: Set $\\gamma \\leftarrow \\infty$ if $q^{(m)} \\in \\mathbb{R}_+^{S^{(m)}}$, $m=1,\\ldots,M$, are balanced; otherwise, choose $\\gamma \\in [0,\\infty)$\n",
    "\n",
    "3: **while** not converged **do**\n",
    "\n",
    "**Step 1: average the marginals**\n",
    "\n",
    "4: Compute \n",
    "\n",
    "$$\n",
    "p^k \\leftarrow \\sum_{m=1}^M a_m p^{(m)}\n",
    "$$\n",
    "\n",
    "5: Set $l^k = 1$ if $\\rho \\sqrt{\\sum_{m=1}^M \\frac{\\|p^k - p^{(m)}\\|^2}{S^{(m)}}} \\leq \\gamma$; otherwise, $l^k \\leftarrow \\gamma / \\left(\\rho \\sqrt{\\sum_{m=1}^M \\frac{\\|p^k - p^{(m)}\\|^2}{S^{(m)}}}\\right)$\n",
    "\n",
    "6: Choose an index set $\\emptyset \\neq \\mathcal{M}^k \\subseteq \\{1,\\ldots,M\\}$\n",
    "\n",
    "7: **for** $m \\in \\mathcal{M}^k$ **do**\n",
    "\n",
    "**Step 2: update the $m^{th}$ plan**\n",
    "\n",
    "8: **for** $s = 1,\\ldots,S^{(m)}$ **do**\n",
    "\n",
    "9: Define $w_r \\leftarrow \\theta_{rs}^{(m),k} + 2l^k \\frac{p_r^k - p_r^{(m)}}{S^{(m)}} - \\frac{1}{\\rho} c_{rs}^{(m)}, \\quad r=1,\\ldots,R$,\n",
    "\n",
    "10: Compute $(\\hat{\\pi}_1^{(m)}, \\ldots, \\hat{\\pi}_{RS}^{(m)}) \\leftarrow \\text{Proj}_{\\Delta_R} q_s^{(m)} (w)$\n",
    "\n",
    "11: Update $\\theta_{rs}^{(m),k+1} \\leftarrow \\hat{\\pi}_{rs}^{(m)} - l^k \\frac{p_r^k - p_r^{(m)}}{S^{(m)}}, \\quad r=1,\\ldots,R$,\n",
    "\n",
    "12: **end for**\n",
    "\n",
    "**Step 3: update the $m^{th}$ marginal**\n",
    "\n",
    "13: Update $p_r^{(m)} \\leftarrow \\sum_{s=1}^{S^{(m)}} \\theta_{rs}^{(m),k+1}, \\quad r=1,\\ldots,R$\n",
    "\n",
    "14: **end for**\n",
    "\n",
    "15: **end while**\n",
    "\n",
    "16: Return $\\hat{p} \\leftarrow p^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594f725",
   "metadata": {},
   "source": [
    "The inputs are a cost matrix $c$ and a intial set of plans: $\\theta^0 \\in \\mathbb{R}^{R \\times \\sum_{m=1}^M s^m}$ and the marginals $p^m$. next we may average the marginals: \n",
    "$$\n",
    "p^k = \\sum_{m=1}^M a_m p^{(m)}\n",
    "$$ \n",
    "And choose a $t^k$. For the update of the plans we do:\n",
    "1. Choose a set of indeces (to work with the corresponding plans)\n",
    "2. For each plan $m$ on the indeces, and each column $s = 1,...,S^m$ on the plan:\n",
    "   - Define $w_r$ for each row of the plan ($r=1,...,R$) (So we get, for all of the plan a total of $R*S(m)$ vaues for $w_r$), this leads to a vector $w$ for each column\n",
    "   - Do: $\\text{proj}_{\\Delta_R (q_s^{(m)})}(w) = (\\pi_{1s}^m,...,\\pi_{Rs}^m)$, that is, you project $w$ on the scaled simplex to get a \"new\" version of the column $s$ of the $m$-th \"plan\"\n",
    "   - You follow the uploads: $\\theta_{rs}^{(m),k+1} \\leftarrow \\hat{\\pi}_{rs}^{(m)} - l^k \\frac{p_r^k - p_r^{(m)}}{S^{(m)}}, \\quad r=1,\\ldots,R$, that is the, as you hace a fixed plan, and a fixed column from that plan, you upload the elements of that column following the previous upload.\n",
    "   - After that you upload the marginals:$p_r^{(m)} \\leftarrow \\sum_{s=1}^{S^{(m)}} \\theta_{rs}^{(m),k+1}, \\quad r=1,\\ldots,R$\n",
    "\n",
    "At the end of the inner for (the one who runs on the columns) you get the plan uploated, __here we could implement our previos code (We should see if we do it before or after uloading the marginals)__. After that, at the end of the outer for, you get the plans of $\\mathcal{M}$ uploaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
